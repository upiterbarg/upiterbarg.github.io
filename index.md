---
layout: default
---
## About

I'm a Ph.D. candidate in the [CILVR lab](https://wp.nyu.edu/cilvr/) at [NYU Courant](https://cims.nyu.edu/dynamic/), co-advised by [Rob Fergus](https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php) and [Lerrel Pinto](https://www.lerrelpinto.com/). My research is supported by a [DeepMind Ph.D. Scholarship](https://www.deepmind.com/scholarships) and an [NSF Graduate Research Fellowship](https://www.nsfgrfp.org/resources/about-grfp/).

I'm interested in **reasoning, decision-making, and open-ended interaction with large generative models**. Recently, I've been thinking about:

* How do we go about building agents that can flexibly explore and interact with the world the way we (humans and animals) do? 

* When is next-token prediction a sufficient pretraining objective for text-based decision-making?

* What sort of structures, priors, and training/finetuning/prompting paradigms can enable a large pre-trained model to be an elegant proof solver? To act as an effective surrogate for ODEs/PDEs/non-linear dynamics? To serve as a (truly) universal high-level controller in robotics settings?


My work touches on **generative modeling** and **reinforcement learning** across modalities (vision, natural language processing, simulators, etc.). I'm also broadly interested in differentiable computing. 

I did my undergrad in mathematics at MIT, during which I was exceptionally lucky to be mentored by [Kelsey R. Allen](https://k-r-allen.github.io/), [Gigliola Staffilani](https://math.mit.edu/~gigliola/), [JÃ¶rn Dunkel](https://math.mit.edu/~dunkel/), and [Raffaele Ferrari](http://ferrari.mit.edu/about/). I've spent time at [EPFL LCN](https://lcnwww.epfl.ch/gerstner/), the [Applied Science Team](https://research.google/teams/applied-science/) at Google Research, and [Microsoft Research NYC](https://www.microsoft.com/en-us/research/theme/machine-learning-ai-nyc/).
