---
layout: default
---
## About

I'm a Ph.D. candidate in the [CILVR lab](https://wp.nyu.edu/cilvr/) at [NYU Courant](https://cims.nyu.edu/dynamic/), co-advised by [Rob Fergus](https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php) and [Lerrel Pinto](https://www.lerrelpinto.com/). My research is supported by a [DeepMind Ph.D. Scholarship](https://www.deepmind.com/scholarships) and an [NSF Graduate Research Fellowship](https://www.nsfgrfp.org/resources/about-grfp/).

I'm interested in applying **large generative models** to hard tasks like **code generation, reasoning, decision-making, and open-ended interaction**. Recently, I've been thinking about:

* How should we train LLMs/VLMs to exhibit a better trade-off between compute and performance during inference?

* What is the best way to generate synthetic date for improving language model capabilities?

* When is next-token prediction a sufficient pretraining objective for reasoning and decision-making? How does the structure of pretraining/finetuning data impact the downstream expressivity of model representations?

My work touches on **generative modeling** and **reinforcement learning** across modalities (vision, natural language processing, simulators, etc.). I'm also broadly interested in scientific applications for deep learning, such as weather and climate modeling.

I've spent time at the [AI Frontiers/GenAI Team at Microsoft Research NYC](https://www.microsoft.com/en-us/research/theme/machine-learning-ai-nyc/), the [Applied Science Team](https://research.google/teams/applied-science/) at Google Research, and [EPFL LCN](https://lcnwww.epfl.ch/gerstner/). I did my undergrad in mathematics at MIT, during which I was exceptionally lucky to be mentored by [Kelsey R. Allen](https://k-r-allen.github.io/), [Gigliola Staffilani](https://math.mit.edu/~gigliola/), and [Raffaele Ferrari](http://ferrari.mit.edu/about/).
