---
layout: post
title:  diff History for Neural Language Agents
date:   2024-02-12 00:00:00 +00:00
image: /diff2.png
categories: research
author: "Ulyana Piterbarg, Lerrel Pinto, Rob Fergus"
authors: "<b>Ulyana Piterbarg</b>, Lerrel Pinto, Rob Fergus"
venue: 41st International Conference on Machine Learning (ICML)
code: https://github.com/upiterbarg/diff_history
projectpage: https://diffhistory.github.io
arxiv: https://arxiv.org/abs/2312.07540
---
Neural Language Models (LMs) offer an exciting solution for general-purpose embodied control. However, a key technical issue arises when using an LM-based controller: environment observations must be converted to text, which coupled with history, results in <b>long and verbose textual prompts</b>. As a result, prior work in LM agents is limited to restricted domains with small observation size as well as minimal needs for interaction history or domain-specific instruction tuning. <b>In this paper, we introduce diff history, a simple and highly effective solution to these issues.</b> By applying the Unix diff command on consecutive text observations in the interaction histories used to prompt LM policies, we can both  <b>abstract away redundant information</b> and <b>focus the content of textual input on the salient changes</b> in the environment. On <b>NetHack</b>, an unsolved video game that requires long-horizon reasoning for decision-making, LMs tuned with diff history match state-of-the-art performance for neural agents while needing <b>1800x fewer training data</b> compared to prior work. Even on the simpler <b>BabyAI-Text</b> environment with concise text observations, we find that although  diff history increases the length of prompts, the representation it provides offers a <b>25% improvement</b> in the efficiency of instruction tuning. Further, we show that diffhistory scales favorably across different tuning dataset sizes.


