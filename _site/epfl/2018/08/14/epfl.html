<script src="http://code.jquery.com/jquery-2.1.4.min.js"></script>
<script>
    $(function(){
        $('a').each(function(){
            if ($(this).prop('href') == window.location.href) {
                $(this).addClass('active'); $(this).parents('navbar').addClass('active');
            }
        });
    });
</script>

<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Investigating Option-Conditional Value Prediction in Refinforcement Learning | Ulyana Piterbarg</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Investigating Option-Conditional Value Prediction in Refinforcement Learning" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Supervised by Johanni Brea and Wulfram Gerstner, I investigated the efficacy of option-conditional value prediction in reinforcement learning (RL) by adapting the Value Prediction Network for tabular environments as well as by implementing the algorithm as in Oh et al.’s original paper, using a combination of temporal-difference search (TD search) and n-step Q-learning for training." />
<meta property="og:description" content="Supervised by Johanni Brea and Wulfram Gerstner, I investigated the efficacy of option-conditional value prediction in reinforcement learning (RL) by adapting the Value Prediction Network for tabular environments as well as by implementing the algorithm as in Oh et al.’s original paper, using a combination of temporal-difference search (TD search) and n-step Q-learning for training." />
<link rel="canonical" href="http://localhost:4000/epfl/2018/08/14/epfl.html" />
<meta property="og:url" content="http://localhost:4000/epfl/2018/08/14/epfl.html" />
<meta property="og:site_name" content="Ulyana Piterbarg" />
<meta property="og:image" content="http://localhost:4000/vpn.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-08-14T20:00:00-04:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://localhost:4000/vpn.png" />
<meta property="twitter:title" content="Investigating Option-Conditional Value Prediction in Refinforcement Learning" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/profile.jpg"}},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/epfl/2018/08/14/epfl.html"},"image":"http://localhost:4000/vpn.png","url":"http://localhost:4000/epfl/2018/08/14/epfl.html","headline":"Investigating Option-Conditional Value Prediction in Refinforcement Learning","description":"Supervised by Johanni Brea and Wulfram Gerstner, I investigated the efficacy of option-conditional value prediction in reinforcement learning (RL) by adapting the Value Prediction Network for tabular environments as well as by implementing the algorithm as in Oh et al.’s original paper, using a combination of temporal-difference search (TD search) and n-step Q-learning for training.","dateModified":"2018-08-14T20:00:00-04:00","datePublished":"2018-08-14T20:00:00-04:00","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=b1d40d763ca5b59c5935fa2fa90ff59992af6a9f">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
    <link rel="shortcut icon" type="image/x-icon" href="/assets/img/favicon.ico">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;1,300;1,400;1,600&family=Space+Mono:wght@400;700&display=swap" rel="stylesheet">

    <style type="text/css">
  </style>
</head>
  <body style="background-image:url('/assets/img/neurons3.png')">
    <div class="wrapper">
      <div class="header">
        <img src="/assets/img/profile.jpg" alt="Ulyana Piterbarg"/>
        <h1> Ulyana Piterbarg </h1>
        <p>
          up2021 [at] cims.nyu.edu
        </p>
        <p> 
          [<a href=https://twitter.com/ulyanapiterbarg>Twitter</a>]  [<a href=https://scholar.google.com/citations?user=I5lFCusAAAAJ&hl=en>Google Scholar</a>]
          [<a href=https://github.com/upiterbarg>Github</a>]
          [<a href=assets/docs/CV.pdf>CV</a>]
        </p>
        <div class="navbar">
          <a  class="active" href="/"> Home </a> <a href="/projects"> Projects </a> <a href="/teaching"> Teaching </a>
        </div>
      </div>
      <div class="content">
        <small>14 August 2018</small>
<h1>Investigating Option-Conditional Value Prediction in Refinforcement Learning</h1>

<p class="view">by </p>

<p>Supervised by <a href="https://scholar.google.ch/citations?user=nZ0m0xUAAAAJ&amp;hl=de">Johanni Brea</a> and <a href="https://lcnwww.epfl.ch/gerstner/">Wulfram Gerstner</a>, I investigated the efficacy of option-conditional value prediction in reinforcement learning (RL) by adapting the <a href="https://papers.nips.cc/paper/2017/file/ffbd6cbb019a1413183c8d08f2929307-Paper.pdf">Value Prediction Network</a> for tabular environments as well as by implementing the algorithm as in Oh et al.’s original paper, using a combination of temporal-difference search (TD search) and n-step Q-learning for training.</p>



  <small>tags: <em></em></small>


      </div>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
  </body>
</html>